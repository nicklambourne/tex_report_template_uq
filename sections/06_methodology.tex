\section{Methodology} \label{sec:method}
% • You should provide a brief discussion of the approach, methods, tools that you will use in your project. For example, you can specify that you will use Mininet as your experimental test-bed. At this stage, you might not know which platform or tools you will use, e.g. you might not know yet which controller platform you will use. You can mention that as well, and say that one of the project tasks is to explore the different controllers. 
The following subsections discusses the teams approach for implementing the load-balancer application and how it will interface with the SDN controller. Details regarding the test network, selected load balancing algorithms and the metrics used in evaluating our algorithms can also be found below.
 
\subsection{The Load Balancing Application}
Our team intends to program a Layer 4 load balancing application in Java using the ONOS API to integrate with the controllers northbound interface and enact our chosen load balancing algorithms. This load balancing application will focus on distributing the load across web application servers through software switches, operating on the OpenFlow protocol, to improve the quality of service for end-users.

The OpenFlow protocol, which operates on our software switches, gathers a range of useful statistics that can be utilised by our load balancing application including received and transmitted packets and bytes as well as packet drops and errors \cite{OSS}. This protocol integrates with the ONOS controller which in turn  has a number of services that abstract the southbound interface and will allow our application to utilise the captured information from the switches and hosts and assist in executing the chosen load balancing algorithm \cite{onosAPI}. The \lstinline{DeviceService} is one example of this which provides access to the OpenFlow protocol device statistics through the \lstinline{DefaultPortStatistics} class \cite{onosAPI}. Using these statistics, our load balancing algorithm will determine applicable flow rules to be passed to the network switches, distributing packet traffic amongst the web application servers.  

\subsection{The Test Network}
As previously discussed, we will be testing a load balancing scenario for a web application server. In our test network this will consist of virtual switches and hosts emulated by Mininet with hosts on the network edge running a distributed custom web application server programmed in Python that will reply to HTTP requests. A simple network topology will be used that places an emphasis on balancing the load across the web application servers. This can be seen below in Figure 2.

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{project/proposal/img/simpletopology.jpg} \\[0.2cm]
    \caption{Test Network Topology}
    \label{fig:topology}
\end{figure}

Due to Mininet's ease of use and flexibility, our test network topology can be expanded to encapsulate a larger number of servers or more complex architecture (e.g. fat tree topology) if an opportunity arises. However, the simple topology in Figure 2. will provide an initial platform to ensure all components of the load balancing application are integrated and core functionality can be achieved.     

\subsection{Algorithms Evaluated}
Load balancing algorithms will be implemented in ascending difficulty, using increasingly complex metrics. Initially a Randomized algorithm will be hard-coded into the load balancing application. As packets arrive at a switch, flow rules will be set to distribute a packet to a random application server. Subsequently a Round Robin algorithm will then be implemented that delivers packets to each application server in turn. On successful implementation of the aforementioned algorithms, further possibilities will be explored including the feasibility of implementing algorithms that rely on application server statistics such as least number of connections and least response time at the server. However, further research must be conducted on whether adequate statistics can be efficiently captured to allow these algorithms to operate to an adequate standard. 

The biggest consideration when implementing these algorithms will be ensuring that both the load balancing application framework and the algorithm itself is implemented efficiently, with the controller receiving the bare minimum number of packets required from the network to ensure bandwidth isn’t impacted. An extra layer of complexity is added when considering how to efficiently address each of the packets to the required server at the switch level.  

\subsection{Metrics}
To evaluate the  efficiency of each load balancing algorithm a range of metrics will be utilised, the capture of these metrics will be discussed in Section 5.5 Testing Process, however a list of the predominate metrics are listed below :
\begin{itemize}
    \item Latency: More specifically we will be evaluating the total time for a request to be processed and returned to the client minus the initial DNS lookup and connection times using the P99 (99th percentile) evaluation metric. 
    \item Server Load: Examining each servers total number of current requests over time will determine whether the client requests across the network are in fact evenly distributed amongst each server. This is a prime metric for comparing load balancing algorithms that are dependent on number of packets such as randomized and round robin.
    \item Throughput: Our methodology will be utilising the average number of requests an algorithm can handle over a unit of time as a measure of throughput. This will be essential in determining the efficiency of the load balancing algorithm, especially when conducting a direct comparison between the different load balancing algorithms.
\end{itemize}

\subsection{Network Traffic and Testing}
Once our test network is created and the load balancing application is integrated with the SDN controller we will begin load testing the web application servers using Granata k6, an open source load testing tool, to generate HTTP requests\cite{k6}. This open-source tool is fully configurable to generate a range of different traffic profiles and capture resultant statistics from the network\cite{k6}. Further statistics can also be captured at our custom web application server, and supplemented with Mininet statistics via ONOS, and possibly Wireshark captures as required.

\subsection{GUI}
% Show existing topology UI and our proposed modifications
The existing GUI, like most ONOS functionality, is exposed to the developer for augmentation through an API. This API utilises the same Angular framework used by the existing ONOS GUI elements. Angular elements for these additional features will need to be developed. The underlying data to be communicated in each element will have to be sourced from the controller, or clients themselves, which would necessitate not only the tracking of this information by each client but also its exposure at one or more new HTTP GET endpoints on the client's application server. In this case these endpoints will be pinged by the provider which would then use the the data to update the UI elements.

\begin{figure}[H]
    \centering
    \includegraphics[width=15cm]{project/proposal/img/topology.png}
    \caption{The Topology View of the ONOS GUI - The Host Info Panel is Highlighted \cite{hunt_2016}}
    \label{fig:topo}
\end{figure}

Figure \ref{fig:topo} shows a view of the existing ONOS topology GUI and highlights the host information panel where details about load could be appended. Visual cues could also be added to the topology map and its nodes.